name: Quality Gate

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    paths-ignore:
      - '**/*.md'
      - '**/*.MD'
      - '**/*.png'
      - '**/*.jpg'
      - '**/*.jpeg'
      - '**/*.gif'
      - '**/*.svg'
  workflow_dispatch: {}

concurrency:
  group: "quality-${{ github.event.pull_request.number || github.ref }}"
  cancel-in-progress: true

permissions:
  contents: read

env:
  NODE_VERSION: "20" # LTS; change to "18" if you need older
  PYTHON_VERSION: "3.11"

defaults:
  run:
    shell: bash

jobs:
  quality:
    name: Integration Analysis + Quality Checks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Detect package manager
        id: pm
        run: |
          if [ -f pnpm-lock.yaml ]; then
            echo "manager=pnpm" >> $GITHUB_OUTPUT
          elif [ -f yarn.lock ]; then
            echo "manager=yarn" >> $GITHUB_OUTPUT
          else
            echo "manager=npm" >> $GITHUB_OUTPUT
          fi

      - name: Setup pnpm if needed
        if: steps.pm.outputs.manager == 'pnpm'
        run: |
          corepack enable
          corepack prepare pnpm@latest --activate

      - name: Install deps
        run: |
          set -e
          if [ "${{ steps.pm.outputs.manager }}" = "pnpm" ]; then
            pnpm install --frozen-lockfile || pnpm install
          elif [ "${{ steps.pm.outputs.manager }}" = "yarn" ]; then
            corepack enable
            yarn install --immutable || yarn install
          else
            if [ -f package-lock.json ]; then
              npm ci || npm i
            else
              npm i
            fi
          fi

      - name: Install analysis tools
        run: |
          npm i -g dependency-cruiser madge
          pip install --upgrade pip
          pip install bandit pyflakes flake8

      # -------- Security ----------
      - name: Security audit (dependencies)
        continue-on-error: true
        run: |
          if [ "${{ steps.pm.outputs.manager }}" = "pnpm" ]; then
            pnpm audit --audit-level=moderate || true
          elif [ "${{ steps.pm.outputs.manager }}" = "yarn" ]; then
            yarn npm audit --audit-level moderate || true
          else
            npm audit --audit-level=moderate || true
          fi

      - name: Python security scan
        continue-on-error: true
        run: |
          if find . -name "*.py" -not -path "./venv/*" -not -path "./.venv/*" | head -1 | grep -q ".py"; then
            bandit -r . -f json -o bandit-report.json || true
            if [ -f bandit-report.json ]; then
              echo "## Python Security Scan" >> $GITHUB_STEP_SUMMARY
              cat bandit-report.json | jq -r '.results[] | "âš ï¸ " + .test_name + ": " + .issue_text' >> $GITHUB_STEP_SUMMARY || true
            fi
          fi

      # ------ Dependency / Integration Diagnostics -------
      - name: Analyze component dependencies
        continue-on-error: true
        run: |
          cat > .dependency-cruiser.js <<'EOF'
          module.exports = {
            forbidden: [
              { name: 'no-circular', severity: 'error', from: {}, to: { circular: true } },
              {
                name: 'diagnostic-session-isolation',
                severity: 'warn',
                comment: 'DiagnosticSession should not directly import from lib/scans',
                from: { path: 'src/pages/DiagnosticSession\\.jsx$' },
                to: { path: 'src/lib/scans\\.' }
              },
              {
                name: 'offline-queue-integrity',
                severity: 'error',
                comment: 'Offline queue should not import from components/pages',
                from: { path: 'src/lib/offlineQueue\\.' },
                to: { path: 'src/(pages|components)/' }
              },
              {
                name: 'health-score-purity',
                severity: 'warn',
                comment: 'Health score should be pure - no side effects',
                from: { path: 'src/utils/healthScore\\.' },
                to: { path: 'src/(lib|api)/' }
              }
            ],
            options: {
              doNotFollow: { path: 'node_modules' },
              includeOnly: { path: '^src/' },
              tsPreCompilationDeps: true,
              enhancedResolveOptions: { exportsFields: ['exports'] }
            }
          };
          EOF

          npx depcruise --validate .dependency-cruiser.js src/ > deps-report.txt 2>&1 || true
          npx madge --image deps-graph.svg --exclude node_modules src/ || true

          echo "## Dependency Analysis" >> $GITHUB_STEP_SUMMARY
          if grep -Eiq "error|warn" deps-report.txt; then
            echo "**Issues found:**" >> $GITHUB_STEP_SUMMARY
            grep -E "error|warn" deps-report.txt | head -10 >> $GITHUB_STEP_SUMMARY
          else
            echo "âœ… No dependency issues detected" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Validate Python-React bridge contracts
        continue-on-error: true
        run: |
          cat > validate-contracts.py <<'EOF'
          import re
          from pathlib import Path

          def find_api_endpoints():
              endpoints = {}
              for py_file in Path('.').rglob('*.py'):
                  p = str(py_file)
                  if '/venv/' in p or '/.venv/' in p:
                      continue
                  try:
                      content = py_file.read_text(encoding='utf-8', errors='ignore')
                      routes = []
                      routes += re.findall(r'@app\\.route\\([\'"]([^\'"]+)[\'"].*?\\)\\s*def\\s+(\\w+)', content, flags=re.S)
                      routes += [(f"{m.upper()} {p}", f) for m,p,f in re.findall(
                          r'@(get|post|put|delete)\\([\'"]([^\'"]+)[\'"].*?\\)\\s*(?:async\\s+)?def\\s+(\\w+)',
                          content, flags=re.S)]
                      for k,v in routes:
                          endpoints[k] = {'file': str(py_file), 'function': v}
                  except Exception as e:
                      print(f"Error parsing {py_file}: {e}")
              return endpoints

          def find_frontend_api_calls():
              api_calls = []
              exts = ('.js', '.jsx', '.ts', '.tsx')
              for js_file in Path('src').rglob('*'):
                  if not js_file.suffix in exts:
                      continue
                  try:
                      content = js_file.read_text(encoding='utf-8', errors='ignore')
                      fetch_calls = re.findall(r'fetch\\([\'"`]([^\'"`;]+)[\'"`]', content)
                      axios_calls = re.findall(r'axios\\.\\w+\\([\'"`]([^\'"`;]+)[\'"`]', content)
                      for call in fetch_calls + axios_calls:
                          if call.startswith('/'):
                              api_calls.append({'path': call, 'file': str(js_file)})
                  except Exception as e:
                      print(f"Error parsing {js_file}: {e}")
              return api_calls

          print("## API Contract Analysis")
          backend_endpoints = find_api_endpoints()
          frontend_calls = find_frontend_api_calls()

          backend_paths = set(backend_endpoints.keys())
          frontend_paths = set(c['path'] for c in frontend_calls)

          issues = []
          orphaned_backend = {p for p in backend_paths if not any(p.endswith(x) or p.split()[-1] == x for x in frontend_paths)}
          orphaned_frontend = {p for p in frontend_paths if not any(p.endswith(x) or p.split()[-1] == x for x in backend_paths)}

          if orphaned_backend:
              issues.append(f"ðŸ”¸ Unused backend endpoints: {', '.join(list(orphaned_backend)[:5])}")
          if orphaned_frontend:
              issues.append(f"ðŸ”¸ Unmatched frontend calls: {', '.join(list(orphaned_frontend)[:5])}")

          required = ['/health', '/faults', '/live']
          missing = [ep for ep in required if not any(ep in path for path in backend_paths)]
          if missing:
              issues.append(f"ðŸ”¸ Missing diagnostic endpoints: {', '.join(missing)}")

          if issues:
              print("\\n".join(issues))
          else:
              print("âœ… API contracts look consistent")
          EOF

          python validate-contracts.py >> $GITHUB_STEP_SUMMARY

      - name: Analyze React hook dependencies
        continue-on-error: true
        run: |
          cat > analyze-hooks.js <<'EOF'
          const fs = require('fs');
          const path = require('path');

          function findFiles(dir) {
            const out = [];
            if (!fs.existsSync(dir)) return out;
            for (const ent of fs.readdirSync(dir)) {
              const p = path.join(dir, ent);
              const st = fs.statSync(p);
              if (st.isDirectory() && ent !== 'node_modules') out.push(...findFiles(p));
              else if (/\.(jsx?|tsx?)$/.test(ent)) out.push(p);
            }
            return out;
          }

          function analyze(content, file) {
            const issues = [];
            const hook = /use(Effect|Memo|Callback)\s*\(\s*([\s\S]*?)\s*,\s*\[([^\]]*)\]/g;
            let m;
            while ((m = hook.exec(content)) !== null) {
              const [, kind, callbackCode, depsArray] = m;
              const used = new Set();
              const varRx = /\b[a-zA-Z_$][a-zA-Z0-9_$]*\b/g;
              let vm;
              while ((vm = varRx.exec(callbackCode)) !== null) {
                const v = vm[0];
                if (!['const','let','var','function','return','if','else','Date','Math','console','window','document'].includes(v)) {
                  used.add(v);
                }
              }
              const declared = new Set(depsArray.split(',').map(s => s.trim().replace(/['"]/g,'')).filter(Boolean));
              const diag = ['entries','health','socket','obdData','filters','obdSocket'];
              const missing = diag.filter(v => used.has(v) && !declared.has(v));
              if (missing.length) issues.push(`${file}: ${kind} missing deps: ${missing.join(', ')}`);
            }
            return issues;
          }

          console.log('\n## React Hook Dependencies');
          const files = findFiles('src');
          const all = [];
          for (const f of files) {
            try {
              all.push(...analyze(fs.readFileSync(f,'utf8'), f));
            } catch {}
          }
          if (all.length) {
            console.log('**Potential missing dependencies:**');
            all.slice(0, 10).forEach(i => console.log(`- ${i}`));
          } else {
            console.log('âœ… No obvious hook dependency issues found');
          }
          EOF

          node analyze-hooks.js >> $GITHUB_STEP_SUMMARY

      - name: Validate diagnostic data flow patterns
        continue-on-error: true
        run: |
          cat > analyze-dataflow.js <<'EOF'
          const fs = require('fs');

          function has(p, s) {
            return fs.existsSync(p) && fs.readFileSync(p,'utf8').includes(s);
          }

          const issues = [];
          const diag = 'src/pages/DiagnosticSession.jsx';
          if (fs.existsSync(diag)) {
            const c = fs.readFileSync(diag,'utf8');
            if (!/useObdSocket|obdSocket/.test(c)) issues.push('DiagnosticSession: Missing OBD socket integration');
            if (!/computeHealthScore|healthScore/.test(c)) issues.push('DiagnosticSession: Missing health score integration');
            if (!/saveScan|queueScan/.test(c)) issues.push('DiagnosticSession: Missing offline persistence');
            if (!/try\s*{[\s\S]*?}\s*catch/.test(c)) issues.push('DiagnosticSession: Missing error handling');
          }
          if (fs.existsSync('src/utils/healthScore.js')) {
            const c = fs.readFileSync('src/utils/healthScore.js','utf8');
            if (!/score/.test(c) || !/confidence/.test(c)) issues.push('healthScore: Inconsistent return structure');
            if (!/Array\.isArray|length/.test(c)) issues.push('healthScore: Missing input validation');
          }
          const q = ['src/lib/offlineQueue.ts','src/lib/offlineQueue.js'].find(fs.existsSync);
          if (q) {
            const c = fs.readFileSync(q,'utf8');
            if (!/localStorage|IndexedDB/.test(c)) issues.push('offlineQueue: Missing persistent storage');
            if (!/navigator\.onLine|online/.test(c)) issues.push('offlineQueue: Missing online/offline detection');
          }

          console.log('\n## Data Flow Analysis');
          if (issues.length) {
            console.log('**Integration issues found:**');
            issues.forEach(i => console.log('- ' + i));
          } else {
            console.log('âœ… Data flow patterns look good');
          }
          EOF

          node analyze-dataflow.js >> $GITHUB_STEP_SUMMARY

      # -------- Standard quality checks ----------
      - name: Lint (ESLint)
        continue-on-error: true
        run: |
          if npx --yes eslint -v >/dev/null 2>&1; then
            npx --yes eslint . || echo "::warning::ESLint issues found"
          fi

      - name: Type check (TypeScript)
        continue-on-error: true
        run: |
          if [ -f tsconfig.json ]; then
            npx --yes tsc --noEmit || echo "::warning::TypeScript issues found"
          fi

      - name: Build
        run: |
          if npx --yes vite -v >/dev/null 2>&1 || [ -f vite.config.ts ] || [ -f vite.config.js ]; then
            if [ "${{ steps.pm.outputs.manager }}" = "pnpm" ]; then pnpm run build
            elif [ "${{ steps.pm.outputs.manager }}" = "yarn" ]; then yarn build
            else npm run build
            fi
          fi

      - name: Test
        continue-on-error: true
        run: |
          if npx --yes vitest --version >/dev/null 2>&1; then
            npx --yes vitest run --reporter=verbose || true
          elif npx --yes jest --version >/dev/null 2>&1; then
            npx --yes jest --ci || true
          fi

      - name: Coverage
        continue-on-error: true
        run: |
          if npx --yes vitest --version >/dev/null 2>&1; then
            npx --yes vitest run --coverage || true
          elif npx --yes jest --version >/dev/null 2>&1; then
            npx --yes jest --coverage || true
          fi

      - name: Enforce coverage thresholds
        run: |
          THRESH_GLOBAL=70
          FILE=$(ls -1 coverage/**/coverage-summary.json 2>/dev/null | head -n1)
          if [ -z "$FILE" ]; then
            echo "No coverage summary found"; exit 0
          fi
          TOTAL=$(cat "$FILE" | jq '.total.statements.pct|floor' 2>/dev/null || echo 0)
          echo "Coverage: ${TOTAL}%"
          if [ "${TOTAL:-0}" -lt "$THRESH_GLOBAL" ]; then
            echo "::error::Coverage ${TOTAL}% below threshold ${THRESH_GLOBAL}%"
            exit 1
          fi

      - name: Bundle size check
        run: |
          if [ -d dist ]; then
            BYTES=$(du -sb dist | awk '{print $1}')
            KB=$((BYTES/1024))
            echo "Bundle size: ${KB} KB"
            MAX_KB=15000
            if [ "$KB" -gt "$MAX_KB" ]; then
              echo "::error::Bundle size ${KB} KB exceeds budget ${MAX_KB} KB"
              exit 1
            fi
            echo "## Bundle Size: ${KB} KB" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Performance benchmark (healthScore)
        env:
          PERF_BUDGET_MS: "250"
          PERF_RUNS: "20"
          PERF_WARMUP: "5"
        run: |
          if [ -f scripts/healthscore-bench.mjs ]; then
            node scripts/healthscore-bench.mjs
          else
            echo "Performance benchmark script not found, skipping"
          fi

      - name: Python lint
        continue-on-error: true
        run: |
          if find . -name "*.py" -not -path "./venv/*" -not -path "./.venv/*" | head -1 | grep -q ".py"; then
            flake8 . || echo "::warning::Python linting issues found"
          fi

      - name: Accessibility smoke test
        continue-on-error: true
        run: |
          if [ -d dist ]; then
            npx -y http-server dist -p 4173 >/dev/null 2>&1 &
            SRV_PID=$!
            sleep 3
            npx -y pa11y http://127.0.0.1:4173/ --threshold 5 || true
            npx -y pa11y http://127.0.0.1:4173/diagnostics --threshold 5 || true
            kill $SRV_PID || true
          fi

      - name: Upload analysis reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports
          path: |
            deps-report.txt
            deps-graph.svg
            bandit-report.json
            coverage/**/coverage-summary.json
          if-no-files-found: ignore
